{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# from hmm_class.hmmd_scaled import HMM\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tknzr = TweetTokenizer(preserve_case=True, strip_handles=False, reduce_len=False)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for getting the word and NER tag pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuples(dspath):\n",
    "    sentences = []\n",
    "    s = ''\n",
    "    tokens = []\n",
    "    ners = []\n",
    "    poss = []\n",
    "    tot_sentences = 0\n",
    "    ners_by_position = []\n",
    "    index = 0\n",
    "    with open(dspath) as f:\n",
    "        for line in f:\n",
    "            if line.strip() != '':\n",
    "                token = line.split('\\t')[0].decode('utf-8')\n",
    "                ner = line.split('\\t')[1].replace('\\r', '').replace('\\n', '').decode('utf-8')\n",
    "                '''\n",
    "                if ner in definitions.NER_TAGS_ORG:\n",
    "                    ner = 'ORG'\n",
    "                elif ner in definitions.NER_TAGS_LOC:\n",
    "                    ner = 'LOC'\n",
    "                elif ner in definitions.NER_TAGS_PER:\n",
    "                    ner = 'PER'\n",
    "                else :\n",
    "                    ner = 'O'\n",
    "                '''\n",
    "                #ners_by_position.append([index, len(token), ner])\n",
    "                index += len(token) + 1\n",
    "            if line.strip() == '':\n",
    "                if len(tokens) != 0:\n",
    "                    #poss = [x[1].decode('utf-8') for x in nltk.pos_tag(nltk.word_tokenize(s[:-1]))]\n",
    "                    poss = [x[1].decode('utf-8') for x in nltk.pos_tag(tknzr.tokenize(s[:-1]))]\n",
    "\n",
    "\n",
    "                    #if len(poss) == len(tokens): # tokenization doesnt affect position of NERs, i.e., same tokenization\n",
    "                    sentences.append(zip(tokens, poss, ners))\n",
    "                    #else:\n",
    "                    #    aux = 0\n",
    "                    #    for i in range(len()):\n",
    "                    #        if aux <= tokens[i]\n",
    "\n",
    "                    tokens = []\n",
    "                    ners = []\n",
    "                    s = ''\n",
    "                    tot_sentences += 1\n",
    "            else:\n",
    "                s += token + ' '\n",
    "                tokens.append(token)\n",
    "                ners.append(ner)\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to creating the feature vectors from the wrods and applying the classification on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1].encode(\"utf-8\")\n",
    "\n",
    "    #my addition\n",
    "    ner_class = sent[i][2].encode(\"utf-8\")\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2].encode(\"utf-8\"),\n",
    "        'stop_word': word in stop,\n",
    "        'hyphen': '-' in word,\n",
    "        'size_small': True if len(word) <= 2 else False,\n",
    "        'stemmer_lanc': lancaster_stemmer.stem(word),\n",
    "\n",
    "        #my addition\n",
    "        #'NER_class': ner_class\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1].encode(\"utf-8\")\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2].encode(\"utf-8\"),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1].encode(\"utf-8\")\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2].encode(\"utf-8\"),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def word2features_new(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1].encode(\"utf-8\")\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2].encode(\"utf-8\"),\n",
    "        'stop_word': word in stop,\n",
    "        'hyphen': '-' in word,\n",
    "        'size_small': True if len(word) <= 2 else False,\n",
    "        'stemmer_lanc': lancaster_stemmer.stem(word),\n",
    "        'klass_1': tf_idf_clone_1.predict([word])[0],\n",
    "        'klass': tf_idf_clone.predict([word])[0],\n",
    "        'klass_2': tf_idf_clone_2.predict([word])[0],\n",
    "        'klass_3': tf_idf_clone_3.predict([word])[0],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1].encode(\"utf-8\")\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2].encode(\"utf-8\"),\n",
    "            '-1:klass': tf_idf_clone.predict([word])[0],\n",
    "            '-1:klass_1': tf_idf_clone_1.predict([word])[0],\n",
    "            '-1:klass_2': tf_idf_clone_2.predict([word])[0],\n",
    "            '-1:klass_3': tf_idf_clone_3.predict([word])[0],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1].encode(\"utf-8\")\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2].encode(\"utf-8\"),\n",
    "            '+1:klass': tf_idf_clone.predict([word])[0],\n",
    "            '+1:klass_1': tf_idf_clone_1.predict([word])[0],\n",
    "            '+1:klass_2': tf_idf_clone_2.predict([word])[0],\n",
    "            '+1:klass_3': tf_idf_clone_3.predict([word])[0],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def remove_extra_features(X_train_new, X_test_new):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    for sentence in X_train_new:\n",
    "        tmp = []\n",
    "        for token in sentence:\n",
    "            del token['klass']\n",
    "            del token['klass_1']\n",
    "            del token['klass_2']\n",
    "            del token['klass_3']\n",
    "\n",
    "            if '+1:klass' in token:\n",
    "                del token['+1:klass']\n",
    "                del token['+1:klass_1']\n",
    "                del token['+1:klass_2']\n",
    "                del token['+1:klass_3']\n",
    "\n",
    "            if '-1:klass' in token:\n",
    "                del token['-1:klass']\n",
    "                del token['-1:klass_1']\n",
    "                del token['-1:klass_2']\n",
    "                del token['-1:klass_3']\n",
    "            tmp.append(token)\n",
    "            X_train.append(tmp)\n",
    "\n",
    "    for sentence in X_test_new:\n",
    "            tmp = []\n",
    "            for token in sentence:\n",
    "\n",
    "                del token['klass']\n",
    "                del token['klass_1']\n",
    "                del token['klass_2']\n",
    "                del token['klass_3']\n",
    "\n",
    "                if '+1:klass' in token:\n",
    "                    del token['+1:klass']\n",
    "                    del token['+1:klass_1']\n",
    "                    del token['+1:klass_2']\n",
    "                    del token['+1:klass_3']\n",
    "\n",
    "                if '-1:klass' in token:\n",
    "                    del token['-1:klass']\n",
    "                    del token['-1:klass_1']\n",
    "                    del token['-1:klass_2']\n",
    "                    del token['-1:klass_3']\n",
    "                tmp.append(token)\n",
    "                X_test.append(tmp)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# Grouping the labels of different dataset\n",
    "def group_labels(labels):\n",
    "    y = []\n",
    "    for string in labels:\n",
    "        temp = []\n",
    "        for tok in string:\n",
    "            if tok.find(\"geo-loc\") != -1 or tok.find(\"location\") != -1:\n",
    "                temp.append(\"LOC\")\n",
    "            elif tok.find(\"company\") != -1 or tok.find(\"corporation\") != -1:\n",
    "                temp.append(\"ORG\")\n",
    "            elif tok.find(\"person\") != -1:\n",
    "                temp.append(\"PER\")\n",
    "            else:\n",
    "                temp.append(\"O\")\n",
    "\n",
    "        y.append(temp)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def group_labels_num(labels):\n",
    "    y = []\n",
    "    for string in labels:\n",
    "        temp = []\n",
    "        for tok in string:\n",
    "            if tok == 1:\n",
    "                temp.append(\"LOC\")\n",
    "            elif tok == 2:\n",
    "                temp.append(\"ORG\")\n",
    "            elif tok == 3:\n",
    "                temp.append(\"PER\")\n",
    "            else:\n",
    "                temp.append(\"O\")\n",
    "\n",
    "        y.append(temp)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features_new(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label.encode(\"utf-8\") for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the before created dataset (saves time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_clone_1 = joblib.load('tf-idf+svm_1.pkl')\n",
    "tf_idf_clone_2 = joblib.load('tf-idf+svm_2.pkl')\n",
    "tf_idf_clone_3 = joblib.load('tf-idf+svm_3.pkl')\n",
    "tf_idf_clone = joblib.load('tf-idf+svm_new.pkl')\n",
    "\n",
    "\n",
    "X_train_ritter = joblib.load('X_train_ritter.pkl')\n",
    "X_train_new_ritter = joblib.load('X_train_new_ritter.pkl')\n",
    "y_train_ritter = joblib.load('y_train_ritter.pkl')\n",
    "\n",
    "X_train_15 = joblib.load('X_train15.pkl')\n",
    "X_train_new_15 = joblib.load('X_train_new15.pkl')\n",
    "y_train_15 = joblib.load('y_train15.pkl')\n",
    "\n",
    "X_train_16 = joblib.load('X_train16.pkl')\n",
    "X_train_new_16 = joblib.load('X_train_new16.pkl')\n",
    "y_train_16 = joblib.load('y_train16.pkl')\n",
    "\n",
    "X_train = X_train_ritter + X_train_15 + X_train_16\n",
    "X_train_new = X_train_new_ritter + X_train_new_15 + X_train_new_16\n",
    "y_train = y_train_ritter + y_train_15 + y_train_16\n",
    "\n",
    "X_test = joblib.load('X_train17.pkl')\n",
    "X_test_new = joblib.load('X_train_new17.pkl')\n",
    "y_test = joblib.load('y_train17.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HMM part - First getting the frequencies of the different entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train, labels, test,testy, split_sequences=False):\n",
    "    # if not os.path.exists('chunking'):\n",
    "    #     print(\"Please create a folder in your local directory called 'chunking'\")\n",
    "    #     print(\"train.txt and test.txt should be stored in there.\")\n",
    "    #     print(\"Please check the comments to get the download link.\")\n",
    "    #     exit()\n",
    "    # elif not os.path.exists('chunking/train.txt'):\n",
    "    #     print(\"train.txt is not in chunking/train.txt\")\n",
    "    #     print(\"Please check the comments to get the download link.\")\n",
    "    #     exit()\n",
    "    # elif not os.path.exists('chunking/test.txt'):\n",
    "    #     print(\"test.txt is not in chunking/test.txt\")\n",
    "    #     print(\"Please check the comments to get the download link.\")\n",
    "    #     exit()\n",
    "\n",
    "    word2idx = {}\n",
    "    tag2idx = {}\n",
    "    word_idx = 0\n",
    "    tag_idx = 0\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    \n",
    "\n",
    "    for line1,line2 in itertools.izip(train,labels):\n",
    "        #print(\"line\")\n",
    "        #print(line)\n",
    "        # line = line.rstrip()\n",
    "        # here should I iterate the list with the lenght and number to get the labels\n",
    "        for pair1,pair2 in itertools.izip(line1,line2):\n",
    "\n",
    "            #if pair:\n",
    "                #print(\"class\")\n",
    "                #r = line.split()\n",
    "\n",
    "            word = tuple(pair1.values())\n",
    "            tag = pair2\n",
    "            #print(tag)\n",
    "            #word, tag = r\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = word_idx\n",
    "                word_idx += 1\n",
    "            currentX.append(word2idx[word])\n",
    "\n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            currentY.append(tag2idx[tag])\n",
    "        if split_sequences:\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "\n",
    "    # load and score test data\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    for line1,line2 in itertools.izip(test,testy):\n",
    "        #print(\"line\")\n",
    "        #print(line)\n",
    "        # line = line.rstrip()\n",
    "        # here should I iterate the list with the lenght and number to get the labels\n",
    "        for pair1,pair2 in itertools.izip(line1,line2):\n",
    "\n",
    "            #if pair:\n",
    "                #r = line.split()\n",
    "            word = tuple(pair1.values())\n",
    "            tag = pair2#[:2]\n",
    "            #word, tag, = r\n",
    "            if word in word2idx:\n",
    "                currentX.append(word2idx[word])\n",
    "            else:\n",
    "                currentX.append(word_idx)  # use this as unknown\n",
    "            currentY.append(tag2idx[tag])\n",
    "        if split_sequences:\n",
    "            Xtest.append(currentX)\n",
    "            Ytest.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, word2idx\n",
    "\n",
    "def random_normalized(d1, d2):\n",
    "    x = np.random.random((d1, d2))\n",
    "    return x / x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM model creation - train the HMM, find the hidden state matrix, create observation matrix, Baum-Welch and Viterbi used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, M):\n",
    "        self.M = M  # number of hidden states\n",
    "\n",
    "    def fit(self, X, max_iter=30):\n",
    "        np.random.seed(123)\n",
    "        # train the HMM model using the Baum-Welch algorithm\n",
    "        # a specific instance of the expectation-maximization algorithm\n",
    "\n",
    "        # determine V, the vocabulary size\n",
    "        # assume observables are already integers from 0..V-1\n",
    "        # X is a jagged array of observed sequences\n",
    "        V = max(max(x) for x in X) + 1\n",
    "        N = len(X)\n",
    "\n",
    "        self.pi = np.ones(self.M) / self.M  # initial state distribution\n",
    "        self.A = random_normalized(self.M, self.M)  # state transition matrix\n",
    "        self.B = random_normalized(self.M, V)  # output distribution\n",
    "\n",
    "        print(\"initial A:\", self.A)\n",
    "        print(\"initial B:\", self.B)\n",
    "\n",
    "        costs = []\n",
    "        for it in range(max_iter):\n",
    "            if it % 10 == 0:\n",
    "                print(\"it:\", it)\n",
    "            # alpha1 = np.zeros((N, self.M))\n",
    "            alphas = []\n",
    "            betas = []\n",
    "            scales = []\n",
    "            logP = np.zeros(N)\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                scale = np.zeros(T)\n",
    "                # alpha1[n] = self.pi*self.B[:,x[0]]\n",
    "                alpha = np.zeros((T, self.M))\n",
    "                alpha[0] = self.pi * self.B[:, x[0]]\n",
    "                scale[0] = alpha[0].sum()\n",
    "                alpha[0] /= scale[0]\n",
    "                for t in range(1, T):\n",
    "                    alpha_t_prime = alpha[t - 1].dot(self.A) * self.B[:, x[t]]\n",
    "                    scale[t] = alpha_t_prime.sum()\n",
    "                    alpha[t] = alpha_t_prime / scale[t]\n",
    "                logP[n] = np.log(scale).sum()\n",
    "                alphas.append(alpha)\n",
    "                scales.append(scale)\n",
    "\n",
    "                beta = np.zeros((T, self.M))\n",
    "                beta[-1] = 1\n",
    "                for t in range(T - 2, -1, -1):\n",
    "                    beta[t] = self.A.dot(self.B[:, x[t + 1]] * beta[t + 1]) / scale[t + 1]\n",
    "                betas.append(beta)\n",
    "\n",
    "            cost = np.sum(logP)\n",
    "            costs.append(cost)\n",
    "\n",
    "            # now re-estimate pi, A, B\n",
    "            self.pi = np.sum((alphas[n][0] * betas[n][0]) for n in range(N)) / N\n",
    "\n",
    "            den1 = np.zeros((self.M, 1))\n",
    "            den2 = np.zeros((self.M, 1))\n",
    "            a_num = np.zeros((self.M, self.M))\n",
    "            b_num = np.zeros((self.M, V))\n",
    "            for n in range(N):\n",
    "                x = X[n]\n",
    "                T = len(x)\n",
    "                den1 += (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims=True).T\n",
    "                den2 += (alphas[n] * betas[n]).sum(axis=0, keepdims=True).T\n",
    "\n",
    "                # numerator for A\n",
    "                # a_num_n = np.zeros((self.M, self.M))\n",
    "                for i in range(self.M):\n",
    "                    for j in range(self.M):\n",
    "                        for t in range(T - 1):\n",
    "                            a_num[i, j] += alphas[n][t, i] * betas[n][t + 1, j] * self.A[i, j] * self.B[j, x[t + 1]] / \\\n",
    "                                           scales[n][t + 1]\n",
    "                # a_num += a_num_n\n",
    "\n",
    "                # numerator for B\n",
    "                # for i in range(self.M):\n",
    "                #     for j in range(V):\n",
    "                #         for t in range(T):\n",
    "                #             if x[t] == j:\n",
    "                #                 b_num[i,j] += alphas[n][t][i] * betas[n][t][i]\n",
    "                for i in range(self.M):\n",
    "                    for t in range(T):\n",
    "                        b_num[i, x[t]] += alphas[n][t, i] * betas[n][t, i]\n",
    "            self.A = a_num / den1\n",
    "            self.B = b_num / den2\n",
    "        print(\"A:\", self.A)\n",
    "        print(\"B:\", self.B)\n",
    "        print(\"pi:\", self.pi)\n",
    "\n",
    "        #plt.plot(costs)\n",
    "        #plt.show()\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        # returns log P(x | model)\n",
    "        # using the forward part of the forward-backward algorithm\n",
    "        T = len(x)\n",
    "        scale = np.zeros(T)\n",
    "        alpha = np.zeros((T, self.M))\n",
    "        alpha[0] = self.pi * self.B[:, x[0]]\n",
    "        scale[0] = alpha[0].sum()\n",
    "        alpha[0] /= scale[0]\n",
    "        for t in range(1, T):\n",
    "            alpha_t_prime = alpha[t - 1].dot(self.A) * self.B[:, x[t]]\n",
    "            scale[t] = alpha_t_prime.sum()\n",
    "            alpha[t] = alpha_t_prime / scale[t]\n",
    "        return np.log(scale).sum()\n",
    "\n",
    "    def log_likelihood_multi(self, X):\n",
    "        return np.array([self.log_likelihood(x) for x in X])\n",
    "\n",
    "    def get_state_sequence(self, x):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm\n",
    "        T = len(x)\n",
    "        delta = np.zeros((T, self.M))\n",
    "        psi = np.zeros((T, self.M))\n",
    "        #print(x)\n",
    "        delta[0] = np.log(self.pi) + np.log(self.B[:, x[0]])\n",
    "        for t in range(1, T):\n",
    "            for j in range(self.M):\n",
    "                delta[t, j] = np.max(delta[t - 1] + np.log(self.A[:, j])) + np.log(self.B[j, x[t]])\n",
    "                psi[t, j] = np.argmax(delta[t - 1] + np.log(self.A[:, j]))\n",
    "\n",
    "        # backtrack\n",
    "        states = np.zeros(T, dtype=np.int32)\n",
    "        states[T - 1] = np.argmax(delta[T - 1])\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            states[t] = psi[t + 1, states[t + 1]]\n",
    "        return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics - Accuracy, F1-Score and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(T, Y):\n",
    "    # inputs are lists of lists\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    for t, y in zip(T, Y):\n",
    "        #print(\"miamano\")\n",
    "        #print(t,y)\n",
    "        for x, z in zip(t, y):\n",
    "            if x != 0:\n",
    "                if x == z:\n",
    "                    n_correct += 1\n",
    "                n_total += 1\n",
    "        #n_correct += np.sum(t == y)\n",
    "        #print(\"The sum\", np.sum(t == y))\n",
    "        #n_total += len(y)\n",
    "    return float(n_correct) / n_total\n",
    "\n",
    "\n",
    "def total_f1_score(T, Y, labels):\n",
    "    # inputs are lists of lists\n",
    "    \n",
    "\n",
    "    T = np.concatenate(T)\n",
    "    Y = np.concatenate(Y)\n",
    "    #print(\"Try to remove: \", labels)\n",
    "    labels.discard(0)\n",
    "    #print(labels)\n",
    "    return f1_score(T, Y, labels=list(labels), average=None).mean()\n",
    "\n",
    "def total_conf_matrix(T, Y):\n",
    "    # inputs are lists of lists\n",
    "    T = np.concatenate(T)\n",
    "    Y = np.concatenate(Y)\n",
    "    return confusion_matrix(T, Y)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting normalize=True.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating HMM class and getting the prediction and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel_launcher.py:122: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test accuracy:', 0.11056682995101469)\n",
      "('test f1:', 0.18998945588656915)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3743d5390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def main( X_train, y_train, X_test, y_test, smoothing=1e-4):\n",
    "    # X = words, Y = NER tags\n",
    "    Xtrain, Ytrain, Xtest, Ytest, word2idx = get_data(X_train, y_train, X_test,y_test, split_sequences=True)\n",
    "    V = len(word2idx) + 1\n",
    "\n",
    "    # find hidden state transition matrix and pi\n",
    "    M = max(max(y) for y in Ytrain) + 1 #len(set(flatten(Ytrain)))\n",
    "    A = np.ones((M, M))*smoothing # add-one smoothing\n",
    "    pi = np.zeros(M)\n",
    "    for y in Ytrain:\n",
    "        pi[y[0]] += 1\n",
    "        for i in range(len(y)-1):\n",
    "            A[y[i], y[i+1]] += 1\n",
    "    # turn it into a probability matrix\n",
    "    A /= A.sum(axis=1, keepdims=True)\n",
    "    pi /= pi.sum()\n",
    "\n",
    "    # find the observation matrix\n",
    "    B = np.ones((M, V))*smoothing # add-one smoothing\n",
    "    for x, y in zip(Xtrain, Ytrain):\n",
    "        for xi, yi in zip(x, y):\n",
    "            B[yi, xi] += 1\n",
    "    B /= B.sum(axis=1, keepdims=True)\n",
    "\n",
    "    hmm = HMM(M)\n",
    "    hmm.pi = pi\n",
    "    hmm.A = A\n",
    "    hmm.B = B\n",
    "\n",
    "    # get predictions\n",
    "    Ptrain = []\n",
    "    for x in Xtrain:\n",
    "        p = hmm.get_state_sequence(x)\n",
    "        Ptrain.append(p)\n",
    "\n",
    "    Ptest = []\n",
    "    #print(hmm.get_state_sequence(Xtrain[0]))\n",
    "    #print(Xtrain[0])\n",
    "    p = hmm.get_state_sequence(Xtrain[0])\n",
    "    #print(p)\n",
    "    for x in Xtest:\n",
    "        if x:\n",
    "            p = hmm.get_state_sequence(x)\n",
    "            Ptest.append(p)\n",
    "    labels=set(flatten(Ytest))\n",
    "    #print(labels)\n",
    "    \n",
    "    # print results\n",
    "    #print(\"train accuracy:\", accuracy(Ytrain, Ptrain))\n",
    "    print(\"The test accuracy and F1-Score:\")\n",
    "    print(\"*********************************************************************\")\n",
    "    print(\"test accuracy:\", accuracy(Ytest, Ptest))\n",
    "    print(\"*********************************************************************\")\n",
    "    #print(\"train f1:\", total_f1_score(Ytrain, Ptrain, labels))\n",
    "    print(\"test f1:\", total_f1_score(Ytest, Ptest, labels))\n",
    "    \n",
    "    cnf_matrix = total_conf_matrix(Ytest, Ptest)\n",
    "    plt.figure()\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix,classes=list(labels), normalize=True,\n",
    "                          title='ncm')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "main( X_train_new, y_train, X_test_new, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python_2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
